from glob import glob
import streamlit as st
from langchain_community.callbacks.manager import get_openai_callback
from PyPDF2 import PdfReader
from langchain_community.llms import OpenAI
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_community.vectorstores import Qdrant
from langchain_qdrant import Qdrant
from langchain.chains import RetrievalQA

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

QDRANT_PATH = "./local_qdrant"
COLLECTION_NAME = "my_collection"

def init_page():
    st.set_page_config(
        page_title="Ask My PDF",
        page_icon="ğŸ¤—",
    )
    st.sidebar.title("Nav")
    st.session_state.costs = []

def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-3.5-16k", "GPT-4"))
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo"
    elif model == "GPT-3.5-16k":
        st.session_state.model_name = "gpt-3.5-turbo-16k"
    else:
        st.session_state.model_name = "gpt-4"
    
    # 300: The number of tokens for instructions outside the main text
    st.session_state.max_token = OpenAI.modelname_to_contextsize(st.session_state.model_name) - 300
    return ChatOpenAI(temperature=0, model_name=st.session_state.model_name)


def get_pdf_text():
    uploaded_file = st.file_uploader(
        label="Upload your PDF here",
        type="pdf", # pdfã‚’æŒ‡å®š
    )
    if uploaded_file:
        pdf_reader = PdfReader(uploaded_file)
        text = "\n\n".join([page.extract_text() for page in pdf_reader.pages])
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            model_name="text-embedding-ada-002",
            chunk_size=250,
            chunk_overlap=0,
        )
        return text_splitter.split_text(text)
    else:
        return None

def load_qdrant():
    client = QdrantClient(path=QDRANT_PATH)

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã™ã¹ã¦å–å¾—
    collections = client.get_collections().collections
    collection_names = [collection.name for collection in collections]

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆ
    if COLLECTION_NAME not in collection_names:
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=1536, distance=Distance.COSINE), # embeddingã®æ¬¡å…ƒ1536, è·é›¢ã‚’ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§å®šç¾©
        )
        print("collection created")
    
    return Qdrant(
        client=client,
        collection_name=COLLECTION_NAME, # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æŒ‡å®š
        embeddings=OpenAIEmbeddings(), # embeddingãƒ¢ãƒ‡ãƒ«ä½œæˆ
    )

# ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ 
def build_vector_store(pdf_text):
    qdrant = load_qdrant() # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    qdrant.add_texts(pdf_text) # textãŒembeddingã«å¤‰æ›ã•ã‚Œã¦DBã«è¿½åŠ ã•ã‚Œã‚‹

def page_pdf_upload_and_build_vector_db():
    st.title("PDF Upload")
    container = st.container()
    with container:
        pdf_text = get_pdf_text()
        if pdf_text:
            with st.spinner("Loading PDF ..."):
                build_vector_store(pdf_text)

# ãƒ™ã‚¯ãƒˆãƒ«DBã‹ã‚‰ä¼¼ãŸæƒ…å ±å–å¾—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
def build_qa_model(llm):
    qdrant = load_qdrant()
    retriever = qdrant.as_retriever(
        search_type="similarity",
        search_kwargs={"k":10},
    )
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        verbose=True,
    )

def ask(qa, query):
    with get_openai_callback() as cb:
        answer = qa.invoke(query)

    return answer, cb.total_cost

def page_ask_my_pdf():
    st.title("Ask My PDF(s)")

    llm = select_model()
    container = st.container()
    response_container = st.container()

    with container:
        query = st.text_input("Query: ", key="input")
        if not query:
            answer = None
        else:
            qa = build_qa_model(llm)
            if qa:
                with st.spinner("ChatGPT is typing ..."):
                    answer, cost = ask(qa, query)
                st.session_state.costs.append(cost)
            else:
                answer = None
        # å‡ºåŠ›è¡¨ç¤º
        if answer:
            with response_container:
                st.markdown("## Answer")
                st.write(answer["result"])

def main():
    init_page()

    selection = st.sidebar.radio("Go to", ["PDF Upload", "Ask My PDF(s)"])
    # ãƒšãƒ¼ã‚¸é·ç§»
    if selection == "PDF Upload":
        page_pdf_upload_and_build_vector_db()
    elif selection == "Ask My PDF(s)":
        page_ask_my_pdf()
    
    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")

if __name__ == "__main__":
    main()